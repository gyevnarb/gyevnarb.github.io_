---
layout: home
---
<hr />
<div class="intro">
    <img src="assets/portrait.jpg" alt="Portrait of Balint" width="250" class="header_img" />
    <strong>Research Postgraduate Student</strong><br />
    <a href="https://edinburghnlp.inf.ed.ac.uk/cdt/">Centre for Doctoral Training in Natural Language Processing</a><br />
    <a href="http://www.ilcc.inf.ed.ac.uk/">Institute for Language, Cognition and Computation</a><br />
    <a href="https://www.ed.ac.uk/">University of Edinburgh</a>
    <p>
    I am a PhD student interested in building trustworthy <em>explainable</em> AI for multi-agent systems, with applications to autonomous vehicles, and an additional focus on AI safety and the law.
    </p>
    <p>
    My supervisors are <a href="https://agents.inf.ed.ac.uk/stefano-albrecht/">Stefano Albrecht</a>, <a href="https://homepages.inf.ed.ac.uk/scohen/">Shay Cohen</a>, and <a href="https://homepages.inf.ed.ac.uk/clucas2/">Chris Lucas</a>.
    </p>
    <span>
    <a href="https://agents.inf.ed.ac.uk/">Agents Group</a>
    &bull;
    <a href="https://twitter.com/CubeCC/">Twitter</a>
    &bull;
    <a href="https://scholar.google.com/citations?user=fLyES3oAAAAJ">Google Scholar</a>
    &bull;
    <a href="https://github.com/gyevnarb/">Github</a>
    </span>
</div>

# Recent highlights

- New survey paper called **["Explainable AI for Safe and Trustworthy Autonomous Driving: A Systematic Review"](https://arxiv.org/abs/2402.10086)** with the first systematic and reproducible review of safe and trustworthy XAI methods for autonomous driving;
- We release a new dataset of 14 driving scenarios and 1300+ annotated human-written explanations called **["HEADD: Human Explanations for Autonomous Driving Decisions"](https://datashare.ed.ac.uk/handle/10283/8714)**;
- Our paper **["Causal Explanations for Sequential Decision-Making in Multi-Agent Systems"](https://arxiv.org/abs/2302.10809)** was accepted at AAMAS-2024;
- Our paper **["Bridging the Transparency Gap: What Can Explainable AI Learn From the AI Act?"](https://arxiv.org/abs/2302.10766)** was accepted at ECAI 2023;
- I was **[awarded £4,000](https://tas.ac.uk/skills/early-career-researcher-awards/)** by the UKRI Trustworthy Autonomous Systems Hub for my work on human-centered social explainable AI;
<!-- - My essay **["Love, Sex, and AI"](assets/essay_lovesexai.pdf)** was selected for publication by the Standing Committee of the AI100 project at Stanford University. -->

<hr />

# About my research
While AI methods have shown impressive results in recent times, they are yet to be widely adopted by the public, especially in high-risk domains such as health care or transportation.
I am interested in combining technologies from explainable AI (XAI), causal reasoning, and natural language processing to support the creation of trustworthy AI systems, focusing especially on the domain of autonomous driving.
In my view, there are four main criteria that trustworthy AI should fulfill:

1. Be lawful. 
There is now a heightened interest from lawmakers to regulate AI technologies, and AI systems will have to adhere to the requirements set out in these laws.

2. Be ethical.
Novel technologies are often plagued by side effects --- AI is no different.
Biased and discriminatory decisions, subversive manipulation of people, and violations of privacy are some of the major concerns that need to be addressed urgently.

3. Be social.
The design of AI systems should consider human interactions as a core part of their workflow.
Conversations and understanding of people's cognitive models should help AI systems create relevant and targeted decisions.

4. Be correct and robust. 
All the above considerations are pointless if the AI systems produce garbage or cannot be deployed under real-life circumstances.
Therefore, the testing and validation of AI systems are essential.

My research focuses on building trustworthy AI for autonomous vehicles to support their wider public adoption.
Using XAI, we can reduce the opacity of our systems, enabling accountability, demonstrating legality, and improving testability.
In addition, cognitive modeling and NLP technologies allow us to address the social aspects of trustworthy AI.
I gave a detailed outline of my vision for this project in an award-winning [essay](assets/IEEE_ITS_Essay.pdf) and a [blog post](https://agents.inf.ed.ac.uk/blog/explainable-autonomous-vehicle-intelligence/).


## About me

I often spend my free time learning languages. Currently, I speak five. In decreasing order of fluency, these are: Hungarian, English, German, Japanese, and Russian.

I like playing volleyball and I am currently the vice president of the Edinburgh University Volleyball Club.
I play setter.
I also enjoy walking with people among the stark landscapes of the Scottish Highlands and taking some breathtaking photos while enduring harsh weather.

Occasionally, I sit down to practise the piano.
At the moment, I am working through the second movement of Schubert's piano sonata in B-flat major ([D 960](https://youtu.be/MAZ8PA5_gVA)).
Currently, I am reading "Gödel, Escher, Bach: An Eternal Golden Braid" by Douglas R. Hofstadter. 
A list of books I have read since I have begun keeping records is [here](https://www.goodreads.com/review/list/62432429?sort=date_read).

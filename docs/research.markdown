---
title: Research
layout: page
permalink: /research/
---
This page is a collection of current and past research projects ordered by how recently I have worked on the project.


## Generating Human-Centric Causal Explanations in Natural Language for Autonomous Vehicles
The merits and drawbacks of autonomous vehicles are a highly contentious topic.
On the one hand, they are predicted to improve transport safety and efficiency, while also making car-based transportation more accessible for people.
On the other hand, autonomous vehicles are complex and integrated systems which are totally opaque to a passenger.
This opaqueness can lead to concerns that the vehicle might fail in unexpected scenarios, fostering distrust and scepticism in people.

In this project, my goal is to build *trust* and *understanding* in people for autonomous vehicles through explanations.
I focus on explaining the complex high-level motion planning and prediction decisions of autonomous vehicles.
The system that provides these decisions is the **transparent** interpretable system IGP2.
I aim to build an automatic explanation generation method for IGP2 that is grounded in accurate **causal** attributions.
The final system should take into consideration the cognitive biases of people, while also being able to run a smooth conversation during its explanations process.
This **social** nature is to guarantee that the generated explanations are as beneficial for our passengers as possible.


## Interpretable Goal-based Prediction and Planning for Autonomous Driving (IGP2)
I am the primary maintainer of the official code repository of [IGP2 on Github](https://github.com/uoe-agents/IGP2) with more than 40 stars and 10 forks.
Our code provides the full functionality of IGP2 and is tightly integrated with the [CARLA driving environment](https://carla.org/) to support high-fidelity simulations.

[IGP2](https://www.five.ai/igp2) is a transparent goal-based prediction and planning module for autonomous vehicles.
It uses a library of high-level driving behaviours called macro actions, such Exit and Continue, that have intuitive interpretations.
This allows us to give explanations of the generated plans of IGP2 in terms of rationality principles.
IGP2 can not only discover non-trivial opportunities by reasoning about the behaviour of other vehicles, but its inherent interpretability is a hugely desirable property in the safety critical world of autonomous driving.

## GRIT: Fast, Interpretable, and Verifiable Goal Recognition with Learned Decision Trees for Autonomous Driving

## Communicative Efficiency or Iconic Learning: Do developmental and communicative pressures interact to shape colour naming systems?

# Old:

## Master's Thesis -- Comparison of Account Survival on Twitter During the First Wave of COVID-19 in Four Countries

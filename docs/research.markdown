---
title: Research
layout: page
permalink: /research/
---
This page is a collection of current and past research projects ordered by how recently I have worked on the project.

## Generating Human-Centric Causal Explanations in Natural Language for Autonomous Vehicles
The merits and drawbacks of autonomous vehicles are a highly contentious topic.
On one hand, they are predicted to improve transport safety and efficiency, while also making car-based transportation more accessible for people.
On the other hand, autonomous vehicles are complex and integrated systems which are totally opaque to a passenger.
This opaqueness can lead to concerns that the vehicle might fail in unexpected scenarios, fostering distrust and scepticism in people.

In this project, my goal is to build *trust* and *understanding* in people for autonomous vehicles through explanations.
I focus on explaining the complex high-level motion planning and prediction decisions of autonomous vehicles.
The system that provides these decisions is the **transparent** interpretable system [IGP2](https://www.five.ai/igp2).
I aim to build an automatic explanation generation method for IGP2 that is grounded in accurate **causal** attributions.
The final system should take into consideration the cognitive biases of people, while also being able to run a smooth conversation during its explanations process.
This **social** nature is to guarantee that the generated explanations are as beneficial for our passengers as possible.


## Communicative Efficiency or Iconic Learning: Do developmental and communicative pressures interact to shape colour naming systems?

## Interpretable Goal-based Prediction and Planning for Autonomous Driving (IGP2)

## GRIT: Fast, Interpretable, and Verifiable Goal Recognition with Learned Decision Trees for Autonomous Driving

# Old:

## Master's Thesis -- Comparison of Account Survival on Twitter During the First Wave of COVID-19 in Four Countries
